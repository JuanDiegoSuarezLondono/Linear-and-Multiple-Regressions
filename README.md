# Linear and Multiple Regressions

Welcome to the Linear and Multiple Regressions repository! This repository covers essential concepts and techniques in linear and multiple regressions, from basic principles to practical applications.

## Table of Contents

- Overview: Linear Regression
    - Mini-Lesson 7.1: What Is Regression?
    - Creating a Plotly and Scikit-Learn Model
    - Codio Activity 7.1: Fitting a Simple Regression Line Using Plotly and Scikit-Learn
        - Problem 1 Fitting a Simple Regression Line Using Plotly and Scikit-Learn
        - Problem 2 Fitting a Simple Regression Line Using Plotly and Scikit-Learn
        - Problem 3 Fitting a Simple Regression Line Using Plotly and Scikit-Learn
        - Problem 4 Fitting a Simple Regression Line Using Plotly and Scikit-Learn
- Overview: Computing Loss
    - Computing the L2 Loss and MSE
    - Understanding that MSE is a Function of One Variable (Theta)
    - Codio Activity 7.2: Defining, Computing, and Optimizing Loss
        - Problem 1 Defining, Computing, and Optimizing Loss
        - Problem 2 Defining, Computing, and Optimizing Loss
        - Problem 3 Defining, Computing, and Optimizing Loss
        - Problem 4 Defining, Computing, and Optimizing Loss
        - Problem 5 Defining, Computing, and Optimizing Loss
    - Minimizing a Function Using Scipy Optimize
    - Codio Activity 7.3: Using SciPy Optimize To Optimize L2 Loss
        - Problem 1 Using SciPy Optimize To Optimize L2 Loss
        - Problem 2 Using SciPy Optimize To Optimize L2 Loss
        - Problem 3 Using SciPy Optimize To Optimize L2 Loss
    - Mini-Lesson 7.2: Different Types of Loss
        - Mean squared error (MSE)
        - Huber loss (smooth mean absolute error)
        - Mean squared logarithmic error (MSLE)
        - Mean bias error (MBE)
    - Codio Activity 7.4: Mean Absolute Loss (MAE)
        - Problem 1 Mean Absolute Loss (MAE)
        - Problem 2 Mean Absolute Loss (MAE)
        - Problem 3 Mean Absolute Loss (MAE)
    - Codio Activity 7.5: Calculating Multiple Loss Functions
        - Problem 1 Calculating Multiple Loss Functions
        - Problem 2 Calculating Multiple Loss Functions
        - Problem 3 Calculating Multiple Loss Functions
- Overview: Multiple Linear Regression
    - Multiple Linear Regression
    - Codio Activity 7.6: Multiple Linear Regression
        - Problem 1 Multiple Linear Regression
        - Problem 2 Multiple Linear Regression
        - Problem 3 Multiple Linear Regression
        - Problem 4 Multiple Linear Regression
- Overview: Non-Numeric Features
    - Using Non-numeric Features
    - Codio Activity 7.7: Using Non-Numeric Features
        - Problem 1 Using Non-Numeric Features
        - Problem 2 Using Non-Numeric Features
        - Problem 3 Using Non-Numeric Features
        - Problem 4 Using Non-Numeric Features
        - Problem 5 Using Non-Numeric Features
        - Problem 6 Using Non-Numeric Features
        - Problem 7 Using Non-Numeric Features
        - Problem 8 Using Non-Numeric Features
        - Problem 9 Using Non-Numeric Features
        - Problem 10 Using Non-Numeric Features
- Glossary

## Overview

Welcome to the Linear and Multiple Regressions repository! Here, we delve into the fascinating world of linear and multiple regressions, covering everything from the fundamental principles to practical applications.

### Linear Regression

In this section, we start with the basics by exploring what regression is all about. We'll walk you through creating simple regression models using Plotly and Scikit-Learn, providing you with a hands-on understanding of how to fit a simple regression line to your data.

### Computing Loss

Understanding loss functions is crucial for optimizing regression models. We'll cover the computation of the L2 loss and Mean Squared Error (MSE), explaining how MSE relates to the variable Theta. Through practical activities, you'll gain insights into defining, computing, and optimizing loss functions, essential for model evaluation and refinement.

### Multiple Linear Regression

Building upon the foundation of linear regression, we delve into multiple linear regression models. You'll learn how to extend simple regression to handle multiple predictors, enabling you to analyze more complex relationships within your data. Through coding activities, you'll gain proficiency in implementing and interpreting multiple linear regression models.

### Non-Numeric Features

Not all data is numeric, and in this section, we explore how to handle non-numeric features in regression analysis. From encoding categorical variables to dealing with text data, you'll learn essential techniques for incorporating diverse types of features into your regression models.

Get ready to embark on a journey through the principles and techniques of linear and multiple regressions. Each section offers practical insights and hands-on activities to deepen your understanding and enhance your skills. Let's dive in and unlock the power of regression analysis together!
